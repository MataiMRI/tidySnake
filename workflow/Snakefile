configfile: 'config/config.yaml'

from pathlib import Path
from itertools import chain

def list_scans(root_folder, prefix):
    mapping = {}

    for path in Path(root_folder).glob(f"{prefix}*"):
        if not path.is_dir() and not path.suffix == ".zip":
            continue

        infos = [s.lower() for s in path.stem.replace(prefix, "").split("_")]
        if len(infos) == 2:
            infos += ["a"]

        cohort, subject, session = infos

        if path.is_dir():
            mapping[(cohort + subject, session)] = path
        else:
            mapping[(cohort + subject, session)] = path.with_suffix("")

    return mapping

MAPPING = list_scans(config["datadir"], config["ethics_prefix"])
SUBJECTS, SESSIONS = zip(*MAPPING)

rule all:
    localrule: True
    input:
        f"{config['resultsdir']}/.mriqc_completed",
        expand(
            f"{config['resultsdir']}/bids/derivatives/mriqc/sub-{{subject}}_ses-{{session}}_qc.yaml",
            zip,
            subject=SUBJECTS,
            session=SESSIONS
        )

rule unzip:
    input:
        f"{config['datadir']}/{{folder}}.zip"
    output:
        directory(f"{config['datadir']}/{{folder}}")
    wildcard_constraints:
        folder="^((?!\.zip).)*$"  # avoid recursive .zip matching in folder name
    shell:
        "unzip -q -d {output} {input}"

wildcard_constraints:
    # Ensure proper matching in patterns containing "ses-{session}_{entity}",
    # where {entity} can contain multiple BIDS entities. For example, in
    # "ses-a_task-rest_run-001", session is "a" and entity is "task-rest_run-001"
    session="[^-]"

rule tidy_dicoms:
    input:
        lambda wildards: MAPPING[(wildards.subject, wildards.session)]
    output:
        temp(directory("{resultsdir}/tidy/sub_{subject}/ses_{session}"))
    run:
        output_folder = Path(output[0])
        for dicom_file in Path(input[0]).rglob("*.dcm"):
            target_folder = output_folder / dicom_file.parent.name
            target_folder.mkdir(parents=True, exist_ok=True)
            (target_folder / dicom_file.name).symlink_to(dicom_file)

checkpoint heudiconv:
    input:
        "{resultsdir}/tidy/sub_{subject}/ses_{session}"
    output:
        directory("{resultsdir}/bids/sub-{subject}/ses-{session}"),
        directory("{resultsdir}/bids/.heudiconv/{subject}/ses-{session}")
    container:
        "docker://ghcr.io/mataimri/heudiconv:jpeg2000_ci"
    threads: config["heudiconv"]["threads"]
    resources:
        cpus=lambda wildcards, threads: threads,
        mem_mb=config["heudiconv"]["mem_mb"],
        runtime=config["heudiconv"]["time_min"]
    shell:
        "heudiconv "
        "--dicom_dir_template '{wildcards.resultsdir}/tidy/sub_{{subject}}/ses_{{session}}/*/*' "
        "--outdir {wildcards.resultsdir}/bids "
        "--heuristic {config[heudiconv][heuristic]} "
        "--subjects {wildcards.subject} "
        "--ses {wildcards.session} "
        "--converter dcm2niix "
        "--bids notop "
        "--overwrite"

rule bids_template:
    input:
        expand(
            "{{resultsdir}}/bids/sub-{subject}/ses-{session}",
            zip,
            subject=SUBJECTS,
            session=SESSIONS,
        )
    output:
        "{resultsdir}/bids/dataset_description.json"
    container:
        "docker://ghcr.io/mataimri/heudiconv:jpeg2000_ci"
    shell:
        "heudiconv "
        "--files {wildcards.resultsdir}/bids "
        "--heuristic {config[heudiconv][heuristic]} "
        "--command populate-templates"

def get_task(wildcards):
    entities = dict(entity.split("-") for entity in wildcards.entity.split("_"))
    if "task" in entities:
        flag = f"--task-id {entities['task']}"
    else:
        flag = ""
    return flag

def get_run(wildcards):
    entities = dict(entity.split("-") for entity in wildcards.entity.split("_"))
    if "run" in entities:
        flag = f"--run-id {entities['run']}"
    else:
        flag = ""
    return flag

# TODO avoid shared file "dataset_description.json" (use shadow rule?)
# TODO allow additional parameters
# TODO increase verbosity to produce log files?
# TODO track other output files (.json and figures)?
rule mriqc:
    input:
        "{resultsdir}/bids/dataset_description.json",
        "{resultsdir}/bids/sub-{subject}/ses-{session}",
    output:
        "{resultsdir}/bids/derivatives/mriqc/sub-{subject}_ses-{session}_{entity}_{suffix}.html"
    wildcard_constraints:
        suffix="T1w|T2w|bold|dwi"
    container:
        "oras://docker.io/maximerio/mriqc:v1.0.0"
    resources:
        cpus=lambda wildcards, threads: threads,
        mem_mb=config["mriqc"]["mem_mb"],
        runtime=config["mriqc"]["time_min"]
    params:
        mem_gb=int(config["mriqc"]["mem_mb"] / 1000),
        run=get_run,
        task=get_task,
    threads: config["mriqc"]["threads"]
    shell:
        "mriqc {wildcards.resultsdir}/bids {wildcards.resultsdir}/bids/derivatives/mriqc "
        "participant "
        "--participant-label {wildcards.subject} "
        "--session-id {wildcards.session} "
        "--modalities {wildcards.suffix} "
        "--mem-gb {params.mem_gb} "
        "{params.run} "
        "{params.task} "
        "--nprocs {threads} "
        "--no-sub "
        "--work-dir {wildcards.resultsdir}/.mriqc_tmp"

# TODO use a wildcard constrain instead? see if it works with glob_wildcards
MRIQC_MODALITIES = ["T1w", "T2w", "bold", "dwi"]

def find_modalities(subject, session, resultsdir):
    """find BIDS entities, including modalities, from BIDS data folder content"""

    # create a dependency on heudiconv rule output
    checkpoints.heudiconv.get(session=session, subject=subject, resultsdir=resultsdir)

    # find all entities (e.g. runs) and modalities for a subject/session pair
    # TODO check what happens with multiple entities and one suffix
    bids_pattern = (
        f"{resultsdir}/bids/sub-{subject}/ses-{session}"
        f"/{{modality}}/sub-{subject}_ses-{session}_{{entity}}_{{suffix}}.nii.gz"
    )
    found_wildcards = glob_wildcards(bids_pattern)

    # keep only modalities supported by MRIQC
    suffixes = [
        suffix for suffix in found_wildcards.suffix if suffix in MRIQC_MODALITIES
    ]

    return found_wildcards.entity, suffixes

def mriqc_files(subject, session, resultsdir):
    """generate the list of MRIQC report files for a subject/session pair"""
    entities, suffixes = find_modalities(subject, session, resultsdir)
    mriqc_pattern = (
        f"{resultsdir}/bids/derivatives/mriqc/"
        f"sub-{subject}_ses-{session}_{{entity}}_{{suffix}}.html"
    )
    mriqc_files = expand(mriqc_pattern, zip, entity=entities, suffix=suffixes)
    return mriqc_files

def mriqc_files_all(wildcards):
    files = chain.from_iterable(
        mriqc_files(subject, session, wildcards.resultsdir)
        for subject, session in zip(SUBJECTS, SESSIONS)
    )
    return list(files)

rule mriqc_cleanup:
    localrule: True
    input:
        mriqc_files_all
    output:
        touch("{resultsdir}/.mriqc_completed")
    shell:
        "rm -rf {wildcards.resultsdir}/.mriqc_tmp"

def find_anat_template(wildcards):
    """find the first T1w run that can serve as anatomical template"""

    entities, suffixes = find_modalities(
        wildcards.subject, wildcards.session, wildcards.resultsdir
    )
    candidates = sorted(
        entity for entity, suffix in zip(entities, suffixes) if suffix == "T1w"
    )

    if not candidates:
        return None

    return f"sub-{wildcards.subject}_ses-{wildcards.session}_{candidates[0]}_T1w"

rule qc_status:
    localrule: True
    input:
        lambda wildcards: mriqc_files(
            wildcards.subject, wildcards.session, wildcards.resultsdir
        ),
        template=workflow.source_path("templates/qc_status.yaml")
    output:
        "{resultsdir}/bids/derivatives/mriqc/sub-{subject}_ses-{session}_qc.yaml"
    params:
        modalities=lambda wildcards: zip(
            *find_modalities(
                wildcards.subject, wildcards.session, wildcards.resultsdir
            )
        ),
        anat_template=find_anat_template
    template_engine:
        "jinja2"
