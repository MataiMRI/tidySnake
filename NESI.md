#  NeSI

This documentation details how to run the workflow on [NeSI](https://www.nesi.org.nz/) (New Zealand eScience Infrastructure) HPC platform.


## Getting started

First, make sure to be logged on Mahuika, either via SSH or using [Jupyter on NeSI](https//jupyter.nesi.org.nz).

In a terminal, clone this repository within your project folder:

```
cd /nesi/project/PROJECTID/$USER
git clone https://github.com/MataiMRI/tidySnake.git
```

where `PROJECTID` is your project number (e.g. `uoa03264`).

*Note: you only need to do the cloning step once.*

Then change directory to be in the folder of the repository:

```
cd /nesi/project/PROJECTID/$USER/tidySnake
```

and edit the `config.yml` file to set your input dataset and result folder paths, for example using `nano` editor:

```
nano config/config.yaml
```

or the JupyterLab editor if you logged in via Jupyter.

Then, instead of using `snakemake` command directly, we will use the `profiles/nesi/snakemake.sl` script, which takes care of setting up the environment to run Snakemake on NeSI.

First, always do a dry-run and see which files will be (re-)created using:

```
srun --account=PROJECTID --qos=debug profiles/nesi/snakemake.sl -n
```

*Note: The option `--qos=debug` gives a higher priority but can only be used for short-running jobs (max 15 minutes). It's ideal for dry-runs.*

If everything looks good, it is then time to submit the workflow as a Slurm batch job using the `sbatch` command:

```
sbatch --account=PROJECTID profiles/nesi/snakemake.sl
```

This puts the workflow in the Slurm queue, where is should be scheduled to start as soon as resources are available.
This command print a number, the **job ID**, that will be useful to keep track of the execution of the workflow.
Note that you don't need to stay logged in once the job as been submitted.


### Job time limit

By default, the workflow time limit is 2 days.
You can increase it up to 3 weeks by using the `--time` option of `sbatch`.

For example, to increase it to 4 days, use:

```
sbatch --account=PROJECTID --time=04-00:00 profiles/nesi/snakemake.sl
```

If you notice that your current job will run out of time, do not hesitate to send an email to support@nesi.org.nz to ask for an extension, providing the job ID of the workflow.


### Running multiple workflows

You can only run one Snakemake workflow at a time (per project and user).

If you use `sbatch` multiple times, the next execution of the workflow will only start once the current one has finished.


### Snakemake options

You can use all the usual snakemake command line options with `profiles/nesi/snakemake.sl`, by adding then at the end of your `srun` or `sbatch` command.

For example, to run the workflow until the `freesurfer` rule, use:

```
sbatch --account=PROJECTID profiles/nesi/snakemake.sl --until bias_correction
```

See the [README](README.md#Useful-Snakemake-options) document for useful Snakemake options.


## Job management

To check the status of your Slurm job, use:

- either the **Job ID** directly

  ```
  squeue -j JOBID
  ```

- or filtering your job list to find the job by its name

  ```
  squeue --me -n tidy_snake
  ```

If the job does not appear in the list, it means that it has completed.

Use the `sacct` command to check if this has been successful or if it ran into issues:

```
sacct -j JOBID
```

If you need to cancel the workflow, use the `scancel` command as follows:

```
scancel --signal INT --full JOBID
```

*Note: The options `--signal INT` and `--full` are very important to ensure all jobs related to this workflow are properly cancelled, not only the main Snakemake job.*

Additionally, you can instruct Slurm to send you an email when the Slurm job changes states (start, end, failure...).
Add the options `--mail-user` and `--mail-type` when submitting the job with `sbatch`:

```
sbatch --account=PROJECTID --mail-user=MYEMAIL --mail-type=ALL profiles/nesi/snakemake.sl
```

where `MYEMAIL` should be replaced by your actual email address.


## Workflow monitoring

All log files generated by the workflow are saved in the `logs` folder.

While the workflow is running, you can look at messages from Snakemake in the corresponding log file using:

```
cat logs/JOBID-tidy_snake.out
```

or  keep a *live* view of the messages as they are appended to the file as follows:

```
tail -f logs/JOBID-tidy_snake.out
```

and press CTRL-C to get back the command prompt.

Note that every rule also generates a Slurm log file named `logs/RULE_JOBID-RULENAME.out`.
The corresponding job ID `RULE_JOBID` is listed in the `logs/JOBID-tidy_snake.out` log file.
