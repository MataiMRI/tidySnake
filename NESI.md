#  NeSI

This documentation details how to run the workflow on [NeSI](https://www.nesi.org.nz/) (New Zealand eScience Infrastructure) HPC platform.


## Getting started

First, make sure to be logged on Mahuika, either via SSH or using [Jupyter on NeSI](https//jupyter.nesi.org.nz).

In a terminal, clone this repository within your project folder:

```
cd /nesi/project/PROJECTID/$USER
git clone https://github.com/MataiMRI/tidySnake.git
```

where `PROJECTID` is your project number (e.g. `uoaXXXXX`).

*Note: you only need to do the cloning step once.*

Then change directory to be in the folder of the repository:

```
cd /nesi/project/PROJECTID/$USER/tidySnake
```

and edit the `config.yml` file to set your input dataset and result folder paths, for example using `nano` editor:

```
nano config/config.yaml
```

or the JupyterLab editor if you logged in via Jupyter.

Then, instead of using `snakemake` command directly, we will use the `profiles/nesi/snakemake.sl` script, which takes care of setting up the environment to run Snakemake on NeSI.

First, always do a dry-run and see which files will be (re-)created using:

```
srun --account=PROJECTID --qos=debug profiles/nesi/snakemake.sl -n
```

*Note: The option `--qos=debug` gives a higher priority but can only be used for short-running jobs (max 15 minutes). It's ideal for dry-runs.*

If everything looks good, it is then time to submit the workflow as a Slurm batch job using the `sbatch` command:

```
sbatch --account=PROJECTID profiles/nesi/snakemake.sl
```

This puts the workflow in the Slurm queue, where is should be scheduled to start as soon as resources are available.
This command print a number, the **job ID**, that will be useful to keep track of the execution of the workflow.
Note that you don't need to stay logged in once the job as been submitted.


### Job time limit

By default, the workflow time limit is 2 days.
You can increase it up to 3 weeks by using the `--time` option of `sbatch`.

For example, to increase it to 4 days, use:

```
sbatch --account=PROJECTID --time=04-00:00 profiles/nesi/snakemake.sl
```

If you notice that your current job will run out of time, do not hesitate to send an email to support@nesi.org.nz to ask for an extension, providing the job ID of the workflow.


### Concurrent workflows

If you use `sbatch` multiple times from the same workflow folder, executions of the workflow will generally fails except for the first one.
This is normal, as Snakemake "locks" the folder to ensure that multiple workflow runs would not concurrently try to create the same files.

You then have to either wait for the workflow to complete or cancel it (see *Job management* section) before resubmiting a new workflow.


### Snakemake options

You can use all the usual snakemake command line options with `profiles/nesi/snakemake.sl`, by adding then at the end of your `srun` or `sbatch` command.

For example, to run the workflow until the `heudiconv` rule, use:

```
sbatch --account=PROJECTID profiles/nesi/snakemake.sl --until heudiconv
```

See the [README](README.md#Useful-Snakemake-options) document for useful Snakemake options.


## Job management

To check the status of your Slurm job, use:

- either the **Job ID** directly

  ```
  squeue -j JOBID
  ```

- or display a list of all of your jobs

  ```
  squeue --me
  ```

If the job does not appear in the list, it means that it has completed.

Use the `sacct` command to check if this has been successful or if it ran into issues:

```
sacct -j JOBID
```

If you need to cancel the workflow, use the `scancel` command as follows **twice**:

```
scancel --signal INT --full JOBID
```

and double-check that it has been properly canceled via the `squeue` command.

*Note: The options `--signal INT` and `--full` are very important to ensure all jobs related to this workflow are properly cancelled, not only the main Snakemake job.
Using this command once might not terminate the workflow but only related jobs, hence the need to run it twice.*

Additionally, you can instruct Slurm to send you an email when the Slurm job changes states (start, end, failure...).
Add the options `--mail-user` and `--mail-type` when submitting the job with `sbatch`:

```
sbatch --account=PROJECTID --mail-user=MYEMAIL --mail-type=ALL profiles/nesi/snakemake.sl
```

where `MYEMAIL` should be replaced by your actual email address.


## Workflow monitoring

All log files generated by the workflow are saved in the `logs` folder.

While the workflow is running, you can look at messages from Snakemake in the corresponding log file using:

```
cat logs/JOBID-tidy_snake.out
```

or  keep a *live* view of the messages as they are appended to the file as follows:

```
tail -f logs/JOBID-tidy_snake.out
```

and press CTRL-C to get back the command prompt.

Note that every rule also generates a Slurm log file named `logs/RULE_JOBID-RULENAME.out`.
The corresponding job ID `RULE_JOBID` is listed in the `logs/JOBID-tidy_snake.out` log file.
